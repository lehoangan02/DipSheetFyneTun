{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O dataset.zip \"https://huggingface.co/datasets/lehoangan02/nlp/resolve/main/dataset.zip?download=true\"\n",
        "!unzip -q dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://wheels.vllm.ai/nightly\n",
            "Collecting vllm\n",
            "  Using cached https://wheels.vllm.ai/8f8fda261a620234fdeea338f44093d5d8072879/vllm-0.13.0rc2.dev79%2Bg8f8fda261-cp38-abi3-manylinux_2_31_x86_64.whl (474.9 MB)\n",
            "Collecting regex (from vllm)\n",
            "  Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting cachetools (from vllm)\n",
            "  Using cached cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting psutil (from vllm)\n",
            "  Using cached psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting sentencepiece (from vllm)\n",
            "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting numpy (from vllm)\n",
            "  Downloading numpy-2.4.0rc1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting requests>=2.26.0 (from vllm)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm (from vllm)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting blake3 (from vllm)\n",
            "  Using cached blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting py-cpuinfo (from vllm)\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting transformers<5,>=4.56.0 (from vllm)\n",
            "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting tokenizers>=0.21.1 (from vllm)\n",
            "  Downloading tokenizers-0.22.2rc0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting protobuf (from vllm)\n",
            "  Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached fastapi-0.124.2-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting aiohttp (from vllm)\n",
            "  Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting openai>=1.99.1 (from vllm)\n",
            "  Using cached openai-2.11.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pydantic>=2.12.0 (from vllm)\n",
            "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Collecting prometheus_client>=0.18.0 (from vllm)\n",
            "  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pillow (from vllm)\n",
            "  Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Using cached tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
            "  Using cached lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<1.4.0,>=1.3.0 (from vllm)\n",
            "  Using cached llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting outlines_core==0.2.11 (from vllm)\n",
            "  Using cached outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diskcache==5.6.3 (from vllm)\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.27 (from vllm)\n",
            "  Using cached xgrammar-0.1.27-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing_extensions>=4.10 (from vllm)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting filelock>=3.16.1 (from vllm)\n",
            "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Using cached partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pyzmq>=25.0.0 (from vllm)\n",
            "  Using cached pyzmq-27.1.0-cp312-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting msgspec (from vllm)\n",
            "  Using cached msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting gguf>=0.17.0 (from vllm)\n",
            "  Using cached gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.5 (from mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached mistral_common-1.8.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
            "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting pyyaml (from vllm)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting six>=1.16.0 (from vllm)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting setuptools<81.0.0,>=77.0.3 (from vllm)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting einops (from vllm)\n",
            "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting compressed-tensors==0.12.2 (from vllm)\n",
            "  Using cached compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.20.0 (from vllm)\n",
            "  Using cached depyf-0.20.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting cloudpickle (from vllm)\n",
            "  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Using cached watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from vllm)\n",
            "  Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting scipy (from vllm)\n",
            "  Using cached scipy-1.17.0rc1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting ninja (from vllm)\n",
            "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pybase64 (from vllm)\n",
            "  Using cached pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cbor2 (from vllm)\n",
            "  Using cached cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting ijson (from vllm)\n",
            "  Using cached ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting setproctitle (from vllm)\n",
            "  Using cached setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from vllm)\n",
            "  Using cached openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting anthropic==0.71.0 (from vllm)\n",
            "  Using cached anthropic-0.71.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting model-hosting-container-standards<1.0.0,>=0.1.9 (from vllm)\n",
            "  Using cached model_hosting_container_standards-0.1.11-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting mcp (from vllm)\n",
            "  Using cached mcp-1.23.3-py3-none-any.whl.metadata (89 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Using cached numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
            "  Using cached ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting torch==2.9.0 (from vllm)\n",
            "  Using cached torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchaudio==2.9.0 (from vllm)\n",
            "  Using cached torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting torchvision==0.24.0 (from vllm)\n",
            "  Using cached torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting flashinfer-python==0.5.3 (from vllm)\n",
            "  Using cached flashinfer_python-0.5.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from anthropic==0.71.0->vllm)\n",
            "  Using cached anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting distro<2,>=1.7.0 (from anthropic==0.71.0->vllm)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting docstring-parser<1,>=0.15 (from anthropic==0.71.0->vllm)\n",
            "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx<1,>=0.25.0 (from anthropic==0.71.0->vllm)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic==0.71.0->vllm)\n",
            "  Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from anthropic==0.71.0->vllm)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting loguru (from compressed-tensors==0.12.2->vllm)\n",
            "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting astor (from depyf==0.20.0->vllm)\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.20.0->vllm)\n",
            "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting apache-tvm-ffi<0.2,>=0.1 (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached apache_tvm_ffi-0.1.5-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting click (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cudnn-frontend>=1.13.0 (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached nvidia_cudnn_frontend-1.16.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-cutlass-dsl>=4.2.1 (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached nvidia_cutlass_dsl-4.3.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-ml-py (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached nvidia_ml_py-13.590.44-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting packaging>=24.2 (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting tabulate (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
            "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Using cached llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting numpy (from vllm)\n",
            "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting sympy>=1.13.3 (from torch==2.9.0->vllm)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch==2.9.0->vllm)\n",
            "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.9.0->vllm)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch==2.9.0->vllm)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.0->vllm)\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch==2.9.0->vllm)\n",
            "  Using cached triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting starlette<0.51.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached fastapi_cli-0.0.16-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jmespath (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting supervisor>=4.2.0 (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm)\n",
            "  Using cached supervisor-4.3.0-py2.py3-none-any.whl.metadata (87 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.12.0->vllm)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>=2.12.0->vllm)\n",
            "  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic>=2.12.0->vllm)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting click (from flashinfer-python==0.5.3->vllm)\n",
            "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
            "  Using cached msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting cupy-cuda12x (from ray[cgraph]>=2.48.0->vllm)\n",
            "  Using cached cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->vllm)\n",
            "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.26.0->vllm)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->vllm)\n",
            "  Using cached urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.26.0->vllm)\n",
            "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.21.1->vllm)\n",
            "  Using cached huggingface_hub-1.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5,>=4.56.0->vllm)\n",
            "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->vllm)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->vllm)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->vllm)\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->vllm)\n",
            "  Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->vllm)\n",
            "  Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->vllm)\n",
            "  Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->vllm)\n",
            "  Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "Collecting httpx-sse>=0.4 (from mcp->vllm)\n",
            "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp->vllm)\n",
            "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pyjwt>=2.10.1 (from pyjwt[crypto]>=2.10.1->mcp->vllm)\n",
            "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp->vllm)\n",
            "  Using cached sse_starlette-3.0.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached rich_toolkit-0.17.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached fastapi_cloud_cli-0.6.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm)\n",
            "  Downloading hf_xet-1.2.1rc0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.9.0->vllm)\n",
            "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached rpds_py-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting cuda-python>=12.8 (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm)\n",
            "  Using cached cuda_python-13.1.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm)\n",
            "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp->vllm)\n",
            "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.10.1->mcp->vllm)\n",
            "  Using cached cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.9.0->vllm)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm)\n",
            "  Using cached fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting cffi>=2.0.0 (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm)\n",
            "  Using cached cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting cuda-bindings~=13.1.1 (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm)\n",
            "  Using cached cuda_bindings-13.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting cuda-pathfinder~=1.1 (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm)\n",
            "  Using cached cuda_pathfinder-1.3.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached sentry_sdk-3.0.0a7-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fastar>=0.8.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp->vllm)\n",
            "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-sdk>=1.4.0 (from sentry-sdk>=2.20.0->fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-api==1.39.1 (from opentelemetry-sdk>=1.4.0->sentry-sdk>=2.20.0->fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.4.0->sentry-sdk>=2.20.0->fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api==1.39.1->opentelemetry-sdk>=1.4.0->sentry-sdk>=2.20.0->fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.39.1->opentelemetry-sdk>=1.4.0->sentry-sdk>=2.20.0->fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached anthropic-0.71.0-py3-none-any.whl (355 kB)\n",
            "Using cached compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
            "Using cached depyf-0.20.0-py3-none-any.whl (39 kB)\n",
            "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Using cached flashinfer_python-0.5.3-py3-none-any.whl (7.0 MB)\n",
            "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "Using cached lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
            "Using cached numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "Using cached outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Using cached torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "Using cached torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "Using cached torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "Using cached xgrammar-0.1.27-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "Using cached fastapi-0.124.2-py3-none-any.whl (112 kB)\n",
            "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Using cached gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "Using cached llguidance-1.3.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached mistral_common-1.8.6-py3-none-any.whl (6.5 MB)\n",
            "Using cached model_hosting_container_standards-0.1.11-py3-none-any.whl (104 kB)\n",
            "Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "Using cached openai-2.11.0-py3-none-any.whl (1.1 MB)\n",
            "Using cached openai_harmony-0.0.8-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
            "Using cached pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
            "Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "Using cached pyzmq-27.1.0-cp312-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (840 kB)\n",
            "Using cached ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "Downloading tokenizers-0.22.2rc0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "Using cached blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
            "Using cached cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Using cached cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (285 kB)\n",
            "Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
            "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Using cached ijson-3.4.0.post0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (149 kB)\n",
            "Using cached mcp-1.23.3-py3-none-any.whl (231 kB)\n",
            "Using cached msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
            "Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "Using cached partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)\n",
            "Using cached psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
            "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Using cached pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
            "Using cached scipy-1.17.0rc1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "Using cached setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Using cached watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "Using cached apache_tvm_ffi-0.1.5-cp312-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Using cached email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Using cached fastapi_cli-0.0.16-py3-none-any.whl (12 kB)\n",
            "Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
            "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Using cached llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "Using cached msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\n",
            "Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "Using cached nvidia_cudnn_frontend-1.16.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "Using cached nvidia_cutlass_dsl-4.3.3-cp312-cp312-manylinux_2_28_x86_64.whl (58.6 MB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "Using cached pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
            "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Using cached sse_starlette-3.0.3-py3-none-any.whl (11 kB)\n",
            "Using cached starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Using cached supervisor-4.3.0-py2.py3-none-any.whl (320 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
            "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Using cached cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl (112.9 MB)\n",
            "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Using cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Using cached nvidia_ml_py-13.590.44-py3-none-any.whl (50 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "Using cached cuda_python-13.1.1-py3-none-any.whl (8.0 kB)\n",
            "Using cached dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "Using cached fastapi_cloud_cli-0.6.0-py3-none-any.whl (23 kB)\n",
            "Using cached fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading hf_xet-1.2.1rc0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hUsing cached httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
            "Using cached rich_toolkit-0.17.0-py3-none-any.whl (31 kB)\n",
            "Using cached rpds_py-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (394 kB)\n",
            "Using cached typer-0.20.0-py3-none-any.whl (47 kB)\n",
            "Using cached uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "Using cached cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
            "Using cached cuda_bindings-13.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (16.1 MB)\n",
            "Using cached cuda_pathfinder-1.3.3-py3-none-any.whl (27 kB)\n",
            "Using cached fastar-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (821 kB)\n",
            "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Using cached rignore-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n",
            "Using cached sentry_sdk-3.0.0a7-py2.py3-none-any.whl (353 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "Using cached opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: supervisor, py-cpuinfo, nvidia-ml-py, nvidia-cusparselt-cu12, mpmath, fastrlock, zipp, websockets, uvloop, urllib3, typing_extensions, triton, tqdm, tabulate, sympy, sniffio, six, shellingham, setuptools, setproctitle, sentencepiece, safetensors, rpds-py, rignore, regex, pyzmq, pyyaml, python-multipart, python-json-logger, python-dotenv, pyjwt, pygments, pycparser, pycountry, pybase64, psutil, protobuf, propcache, prometheus_client, pillow, partial-json-parser, packaging, outlines_core, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cudnn-frontend, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, networkx, multidict, msgspec, msgpack, mdurl, MarkupSafe, loguru, llvmlite, llguidance, lark, jmespath, jiter, interegular, ijson, idna, httpx-sse, httptools, hf-xet, h11, fsspec, frozenlist, filelock, fastar, einops, docstring-parser, dnspython, distro, diskcache, dill, cuda-pathfinder, cloudpickle, click, charset_normalizer, certifi, cbor2, cachetools, blake3, attrs, astor, annotated-types, annotated-doc, aiohappyeyeballs, yarl, uvicorn, typing-inspection, scipy, requests, referencing, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, jinja2, importlib-metadata, httpcore, gguf, email-validator, depyf, cupy-cuda12x, cuda-bindings, cffi, apache-tvm-ffi, anyio, aiosignal, watchfiles, tiktoken, starlette, sse-starlette, rich, pydantic, opentelemetry-api, nvidia-cusolver-cu12, jsonschema-specifications, huggingface-hub, httpx, cuda-python, cryptography, aiohttp, typer, torch, tokenizers, rich-toolkit, pydantic-settings, pydantic-extra-types, prometheus-fastapi-instrumentator, opentelemetry-semantic-conventions, openai-harmony, openai, nvidia-cutlass-dsl, lm-format-enforcer, jsonschema, fastapi, anthropic, transformers, torchvision, torchaudio, ray, opentelemetry-sdk, model-hosting-container-standards, mcp, flashinfer-python, fastapi-cli, xgrammar, sentry-sdk, mistral_common, compressed-tensors, fastapi-cloud-cli, vllm\n",
            "Successfully installed MarkupSafe-3.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-doc-0.0.4 annotated-types-0.7.0 anthropic-0.71.0 anyio-4.12.0 apache-tvm-ffi-0.1.5 astor-0.8.1 attrs-25.4.0 blake3-1.0.8 cachetools-6.2.2 cbor2-5.7.1 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.2.1 cloudpickle-3.1.2 compressed-tensors-0.12.2 cryptography-46.0.3 cuda-bindings-13.1.1 cuda-pathfinder-1.3.3 cuda-python-13.1.1 cupy-cuda12x-13.6.0 depyf-0.20.0 dill-0.4.0 diskcache-5.6.3 distro-1.9.0 dnspython-2.8.0 docstring-parser-0.17.0 einops-0.8.1 email-validator-2.3.0 fastapi-0.124.2 fastapi-cli-0.0.16 fastapi-cloud-cli-0.6.0 fastar-0.8.0 fastrlock-0.8.3 filelock-3.20.0 flashinfer-python-0.5.3 frozenlist-1.8.0 fsspec-2025.12.0 gguf-0.17.1 h11-0.16.0 hf-xet-1.2.1rc0 httpcore-1.0.9 httptools-0.7.1 httpx-0.28.1 httpx-sse-0.4.3 huggingface-hub-0.36.0 idna-3.11 ijson-3.4.0.post0 importlib-metadata-8.7.0 interegular-0.3.3 jinja2-3.1.6 jiter-0.12.0 jmespath-1.0.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 lark-1.2.2 llguidance-1.3.0 llvmlite-0.44.0 lm-format-enforcer-0.11.3 loguru-0.7.3 markdown-it-py-4.0.0 mcp-1.23.3 mdurl-0.1.2 mistral_common-1.8.6 model-hosting-container-standards-0.1.11 mpmath-1.3.0 msgpack-1.1.2 msgspec-0.20.0 multidict-6.7.0 networkx-3.6.1 ninja-1.13.0 numba-0.61.2 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cudnn-frontend-1.16.0 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-cutlass-dsl-4.3.3 nvidia-ml-py-13.590.44 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 openai-2.11.0 openai-harmony-0.0.8 opencv-python-headless-4.12.0.88 opentelemetry-api-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 outlines_core-0.2.11 packaging-25.0 partial-json-parser-0.2.1.1.post7 pillow-12.0.0 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.23.1 propcache-0.4.1 protobuf-6.33.2 psutil-7.1.3 py-cpuinfo-9.0.0 pybase64-1.4.3 pycountry-24.6.1 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-extra-types-2.10.6 pydantic-settings-2.12.0 pygments-2.19.2 pyjwt-2.10.1 python-dotenv-1.2.1 python-json-logger-4.0.0 python-multipart-0.0.20 pyyaml-6.0.3 pyzmq-27.1.0 ray-2.52.1 referencing-0.37.0 regex-2025.11.3 requests-2.32.5 rich-14.2.0 rich-toolkit-0.17.0 rignore-0.7.6 rpds-py-0.30.0 safetensors-0.7.0 scipy-1.17.0rc1 sentencepiece-0.2.1 sentry-sdk-3.0.0a7 setproctitle-1.3.7 setuptools-80.9.0 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 sse-starlette-3.0.3 starlette-0.50.0 supervisor-4.3.0 sympy-1.14.0 tabulate-0.9.0 tiktoken-0.12.0 tokenizers-0.22.2rc0 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 tqdm-4.67.1 transformers-4.57.3 triton-3.5.0 typer-0.20.0 typing-inspection-0.4.2 typing_extensions-4.15.0 urllib3-2.6.2 uvicorn-0.38.0 uvloop-0.22.1 vllm-0.13.0rc2.dev79+g8f8fda261 watchfiles-1.1.1 websockets-15.0.1 xgrammar-0.1.27 yarl-1.22.0 zipp-3.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in ./myenv/lib/python3.12/site-packages (from jiwer) (8.2.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "from vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from jiwer import cer, wer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-12 16:51:41 [utils.py:253] non-default args: {'enable_prefix_caching': False, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'mm_processor_cache_gb': 0, 'logits_processors': [<class 'vllm.model_executor.models.deepseek_ocr.NGramPerReqLogitsProcessor'>], 'model': 'unsloth/DeepSeek-OCR'}\n",
            "INFO 12-12 16:51:42 [model.py:514] Resolved architecture: DeepseekOCRForCausalLM\n",
            "WARNING 12-12 16:51:42 [model.py:1929] Your device 'NVIDIA T400 4GB' (with compute capability 7.5) doesn't support torch.bfloat16. Falling back to torch.float16 for compatibility.\n",
            "WARNING 12-12 16:51:42 [model.py:1979] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 12-12 16:51:42 [model.py:1636] Using max model len 8192\n",
            "INFO 12-12 16:51:42 [scheduler.py:228] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:647: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:51:52 [core.py:93] Initializing a V1 LLM engine (v0.13.0rc2.dev79+g8f8fda261) with config: model='unsloth/DeepSeek-OCR', speculative_config=None, tokenizer='unsloth/DeepSeek-OCR', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=unsloth/DeepSeek-OCR, enable_prefix_caching=False, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:51:54 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://192.168.1.7:50507 backend=nccl\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:51:54 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:51:54 [fa_utils.py:73] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:52:03 [gpu_model_runner.py:3560] Starting to load model unsloth/DeepSeek-OCR...\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:52:04 [layer.py:527] Using AttentionBackendEnum.TORCH_SDPA for MultiHeadAttention in multimodal encoder.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m /home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:52:06 [cuda.py:412] Using FLASHINFER attention backend out of potential backends: ['FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m INFO 12-12 16:52:06 [layer.py:372] Enabled separate cuda stream for MoE shared_experts\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [gpu_model_runner.py:3655] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 3.62 GiB of which 69.75 MiB is free. Including non-PyTorch memory, this process has 3.00 GiB memory in use. Of the allocated memory 2.92 GiB is allocated by PyTorch, and 21.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866] EngineCore failed to start.\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866] Traceback (most recent call last):\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 857, in run_engine_core\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 637, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     super().__init__(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 102, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.model_executor = executor_class(vllm_config)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/executor/abstract.py\", line 101, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self._init_executor()\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py\", line 48, in _init_executor\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.driver_worker.load_model()\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py\", line 284, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 3656, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     raise e\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 3579, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.model = model_loader.load_model(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py\", line 49, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     model = initialize_model(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]             ^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py\", line 48, in initialize_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_ocr.py\", line 418, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.language_model = init_vllm_registered_model(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py\", line 359, in init_vllm_registered_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     return initialize_model(vllm_config=vllm_config, prefix=prefix)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py\", line 48, in initialize_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1411, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.model = self.model_cls(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                  ^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/compilation/decorators.py\", line 291, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     old_init(self, **kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1268, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                                                     ^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py\", line 606, in make_layers\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1270, in <lambda>\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     lambda prefix: DeepseekV2DecoderLayer(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1164, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.mlp = DeepseekV2MoE(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                ^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 307, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.experts = SharedFusedMoE(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]                    ^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/shared_fused_moe.py\", line 28, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     super().__init__(**kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/layer.py\", line 649, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     self.quant_method.create_weights(layer=self, **moe_quant_params)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py\", line 154, in create_weights\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     torch.empty(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/torch/utils/_device.py\", line 103, in __torch_function__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]     return func(*args, **kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m ERROR 12-12 16:52:06 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 3.62 GiB of which 69.75 MiB is free. Including non-PyTorch memory, this process has 3.00 GiB memory in use. Of the allocated memory 2.92 GiB is allocated by PyTorch, and 21.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m Process EngineCore_DP0:\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m Traceback (most recent call last):\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.run()\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self._target(*self._args, **self._kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 870, in run_engine_core\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     raise e\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 857, in run_engine_core\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     engine_core = EngineCoreProc(*args, **kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 637, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     super().__init__(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core.py\", line 102, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.model_executor = executor_class(vllm_config)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/executor/abstract.py\", line 101, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self._init_executor()\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py\", line 48, in _init_executor\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.driver_worker.load_model()\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py\", line 284, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 3656, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     raise e\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 3579, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.model = model_loader.load_model(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py\", line 49, in load_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     model = initialize_model(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m             ^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py\", line 48, in initialize_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_ocr.py\", line 418, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.language_model = init_vllm_registered_model(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py\", line 359, in init_vllm_registered_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     return initialize_model(vllm_config=vllm_config, prefix=prefix)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py\", line 48, in initialize_model\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1411, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.model = self.model_cls(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                  ^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/compilation/decorators.py\", line 291, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     old_init(self, **kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1268, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                                                     ^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py\", line 606, in make_layers\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1270, in <lambda>\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     lambda prefix: DeepseekV2DecoderLayer(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 1164, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.mlp = DeepseekV2MoE(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                ^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/models/deepseek_v2.py\", line 307, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.experts = SharedFusedMoE(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m                    ^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/shared_fused_moe.py\", line 28, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     super().__init__(**kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/layer.py\", line 649, in __init__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     self.quant_method.create_weights(layer=self, **moe_quant_params)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py\", line 154, in create_weights\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     torch.empty(\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m   File \"/home/lhan/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/torch/utils/_device.py\", line 103, in __torch_function__\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m     return func(*args, **kwargs)\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m            ^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[0;36m(EngineCore_DP0 pid=373202)\u001b[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 280.00 MiB. GPU 0 has a total capacity of 3.62 GiB of which 69.75 MiB is free. Including non-PyTorch memory, this process has 3.00 GiB memory in use. Of the allocated memory 2.92 GiB is allocated by PyTorch, and 21.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "[rank0]:[W1212 16:52:07.340436278 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Engine core initialization failed. See root cause above. Failed core proc(s): {}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munsloth/DeepSeek-OCR\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# <-- THIS IS THE BASELINE\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_prefix_caching\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmm_processor_cache_gb\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mNGramPerReqLogitsProcessor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/entrypoints/llm.py:350\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, runner, convert, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, allowed_media_domains, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, disable_custom_all_reduce, hf_token, hf_overrides, mm_processor_kwargs, pooler_config, structured_outputs_config, profiler_config, kv_cache_memory_bytes, compilation_config, logits_processors, **kwargs)\u001b[39m\n\u001b[32m    315\u001b[39m engine_args = EngineArgs(\n\u001b[32m    316\u001b[39m     model=model,\n\u001b[32m    317\u001b[39m     runner=runner,\n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m     **kwargs,\n\u001b[32m    346\u001b[39m )\n\u001b[32m    348\u001b[39m log_non_default_args(engine_args)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n\u001b[32m    355\u001b[39m \u001b[38;5;28mself\u001b[39m.request_counter = Counter()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:183\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers, enable_multiprocessing)\u001b[39m\n\u001b[32m    180\u001b[39m     enable_multiprocessing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Create the LLMEngine.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:109\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, aggregate_engine_logging, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m.output_processor.tracer = tracer\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCoreClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mself\u001b[39m.logger_manager: StatLoggerManager | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.log_stats:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:93\u001b[39m, in \u001b[36mEngineCoreClient.make_client\u001b[39m\u001b[34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EngineCoreClient.make_async_mp_client(\n\u001b[32m     89\u001b[39m         vllm_config, executor_class, log_stats\n\u001b[32m     90\u001b[39m     )\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multiprocess_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio_mode:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyncMPClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InprocClient(vllm_config, executor_class, log_stats)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:648\u001b[39m, in \u001b[36mSyncMPClient.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    646\u001b[39m     \u001b[38;5;28mself\u001b[39m, vllm_config: VllmConfig, executor_class: \u001b[38;5;28mtype\u001b[39m[Executor], log_stats: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    647\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28mself\u001b[39m.is_dp = \u001b[38;5;28mself\u001b[39m.vllm_config.parallel_config.data_parallel_size > \u001b[32m1\u001b[39m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28mself\u001b[39m.outputs_queue = queue.Queue[EngineCoreOutputs | \u001b[38;5;167;01mException\u001b[39;00m]()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py:477\u001b[39m, in \u001b[36mMPClient.__init__\u001b[39m\u001b[34m(self, asyncio_mode, vllm_config, executor_class, log_stats, client_addresses)\u001b[39m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats_update_address = client_addresses.get(\u001b[33m\"\u001b[39m\u001b[33mstats_update_address\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;66;03m# Engines are managed by this client.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlaunch_core_engines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine_manager\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_manager\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:144\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/utils.py:903\u001b[39m, in \u001b[36mlaunch_core_engines\u001b[39m\u001b[34m(vllm_config, executor_class, log_stats, num_api_servers)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m local_engine_manager, coordinator, addresses\n\u001b[32m    902\u001b[39m \u001b[38;5;66;03m# Now wait for engines to start.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43mwait_for_engine_startup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhandshake_socket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengines_to_handshake\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_engine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.12/site-packages/vllm/v1/engine/utils.py:960\u001b[39m, in \u001b[36mwait_for_engine_startup\u001b[39m\u001b[34m(handshake_socket, addresses, core_engines, parallel_config, cache_config, proc_manager, coord_process)\u001b[39m\n\u001b[32m    958\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coord_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m coord_process.exitcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    959\u001b[39m         finished[coord_process.name] = coord_process.exitcode\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    961\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine core initialization failed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    962\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee root cause above. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    963\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed core proc(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinished\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    964\u001b[39m     )\n\u001b[32m    966\u001b[39m \u001b[38;5;66;03m# Receive HELLO and READY messages from the input socket.\u001b[39;00m\n\u001b[32m    967\u001b[39m eng_identity, ready_msg_bytes = handshake_socket.recv_multipart()\n",
            "\u001b[31mRuntimeError\u001b[39m: Engine core initialization failed. See root cause above. Failed core proc(s): {}"
          ]
        }
      ],
      "source": [
        "llm = LLM(\n",
        "    model=\"unsloth/DeepSeek-OCR\",   # <-- THIS IS THE BASELINE\n",
        "    enable_prefix_caching=False,\n",
        "    mm_processor_cache_gb=0,\n",
        "    logits_processors=[NGramPerReqLogitsProcessor],\n",
        "    gpu_memory_utilization=0.6\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sampling paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampling_param = SamplingParams(\n",
        "    temperature=0.0,\n",
        "    max_tokens=8192,\n",
        "    extra_args=dict(\n",
        "        ngram_size=30,\n",
        "        window_size=90,\n",
        "        whitelist_token_ids={128821, 128822},  # <td> and </td>\n",
        "    ),\n",
        "    skip_special_tokens=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|██████████| 1/1 [00:07<00:00,  7.27s/it]\n",
            "Processed prompts: 100%|██████████| 1/1 [01:17<00:00, 77.69s/it, est. speed input: 11.56 toks/s, output: 0.09 toks/s]\n",
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [01:13<00:00, 73.49s/it, est. speed input: 12.22 toks/s, output: 0.37 toks/s]\n",
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 25.35it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [00:58<00:00, 58.71s/it, est. speed input: 11.89 toks/s, output: 0.07 toks/s]\n",
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [01:24<00:00, 84.05s/it, est. speed input: 10.68 toks/s, output: 0.11 toks/s]\n",
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s]\n",
            "Processed prompts: 100%|██████████| 1/1 [01:31<00:00, 91.02s/it, est. speed input: 5.36 toks/s, output: 0.03 toks/s]\n",
            "Adding requests: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s]\n",
            "  0%|          | 5/2881 [06:36<63:21:59, 79.32s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m image = Image.open(img_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m model_input = [{\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: PROMPT,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmulti_modal_data\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m: image}\n\u001b[32m     20\u001b[39m }]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m out = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m pred = out[\u001b[32m0\u001b[39m].outputs[\u001b[32m0\u001b[39m].text\n\u001b[32m     25\u001b[39m preds.append(pred)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:442\u001b[39m, in \u001b[36mLLM.generate\u001b[39m\u001b[34m(self, prompts, sampling_params, use_tqdm, lora_request, priority)\u001b[39m\n\u001b[32m    432\u001b[39m lora_request = \u001b[38;5;28mself\u001b[39m._get_modality_specific_lora_reqs(prompts, lora_request)\n\u001b[32m    434\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_and_add_requests(\n\u001b[32m    435\u001b[39m     prompts=prompts,\n\u001b[32m    436\u001b[39m     params=sampling_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    439\u001b[39m     priority=priority,\n\u001b[32m    440\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine_class.validate_outputs(outputs, RequestOutput)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:1732\u001b[39m, in \u001b[36mLLM._run_engine\u001b[39m\u001b[34m(self, use_tqdm)\u001b[39m\n\u001b[32m   1730\u001b[39m total_out_toks = \u001b[32m0\u001b[39m\n\u001b[32m   1731\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_engine.has_unfinished_requests():\n\u001b[32m-> \u001b[39m\u001b[32m1732\u001b[39m     step_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1733\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[32m   1734\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m output.finished:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:293\u001b[39m, in \u001b[36mLLMEngine.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# 1) Get EngineCoreOutput from the EngineCore.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record_function_or_nullcontext(\u001b[33m\"\u001b[39m\u001b[33mllm_engine step: get_output\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# 2) Process EngineCoreOutputs.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record_function_or_nullcontext(\u001b[33m\"\u001b[39m\u001b[33mllm_engine step: process_outputs\u001b[39m\u001b[33m\"\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DipSheetFyneTun/myenv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:709\u001b[39m, in \u001b[36mSyncMPClient.get_output\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_output\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> EngineCoreOutputs:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# If an exception arises in process_outputs_socket task,\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;66;03m# it is forwarded to the outputs_queue so we can raise it\u001b[39;00m\n\u001b[32m    708\u001b[39m     \u001b[38;5;66;03m# from this (run_output_handler) task to shut down the server.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutputs_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[32m    711\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_exception(outputs) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR 12-12 16:34:10 [core_client.py:600] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.\n"
          ]
        }
      ],
      "source": [
        "IMG_ROOT = \"dataset/images\"\n",
        "TEST_CSV = \"dataset/test.csv\"\n",
        "PROMPT = \"<image>\\nFree OCR.\"    # same prompt as notebook baseline\n",
        "\n",
        "df = pd.read_csv(TEST_CSV)\n",
        "\n",
        "preds = []\n",
        "gts = []\n",
        "\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    rel = row[\"filepath\"]\n",
        "    gt = str(row[\"text\"])\n",
        "    img_path = os.path.join(IMG_ROOT, rel)\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    model_input = [{\n",
        "        \"prompt\": PROMPT,\n",
        "        \"multi_modal_data\": {\"image\": image}\n",
        "    }]\n",
        "\n",
        "    out = llm.generate(model_input, sampling_param)\n",
        "    pred = out[0].outputs[0].text\n",
        "\n",
        "    preds.append(pred)\n",
        "    gts.append(gt)\n",
        "\n",
        "print(\"CER:\", cer(gts, preds))\n",
        "print(\"WER:\", wer(gts, preds))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03486ecc6fed4a7cb7e2e02dca0dee5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0890359ee9574b19b1b52a4c740fad41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1286473bfcdb4d5f96bc3154c26d72cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "135c7d5ae19a46ee811002c6a139692c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d05bb6c47dc460381c2a6af5266d875": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246d3453758f4803b034aff39adaa8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfbe50fd14240cab4e34052d6f006b9",
            "placeholder": "​",
            "style": "IPY_MODEL_f83610de6c30471ab5d54786fe6236c7",
            "value": " 179999/179999 [00:08&lt;00:00, 67918.40 examples/s]"
          }
        },
        "271457a1a6a2478880ef17c92139a4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d2947e714644297833248cdbbac3216": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d74cb6cfd63483d99cf994bbecf53ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3088b111494643b6bea2575b95888ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f339d93fb044599e575f7971bb890b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89828f4b1f4449e3b52b8951a22054a0",
            "placeholder": "​",
            "style": "IPY_MODEL_0890359ee9574b19b1b52a4c740fad41",
            "value": "Generating test split: 100%"
          }
        },
        "33a933565ab44e2588724492fc084f55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36910390b5da4091846ca5fcfbbf8a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36eadf48405b4d60afdd702c6eabe976": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eaf210f8a434a36bff0ef7b61e53465": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c060dc723d415daf54a4bc703dcea0",
            "placeholder": "​",
            "style": "IPY_MODEL_6a6fc018480541a7aea9b6e137f8f942",
            "value": "README.md: 100%"
          }
        },
        "43bcadc5c612457d8cfb8605889e27a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d4e788c9e3416fbd70cb9f360d7887": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a32cfd5a60a4c18b32f74805aed7f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31f339d93fb044599e575f7971bb890b",
              "IPY_MODEL_8a6700fbe79d40ec8261a68822c8c48f",
              "IPY_MODEL_c31f976abb564d769ea56ebad2dc3ee3"
            ],
            "layout": "IPY_MODEL_f769ee16de144e22a1ed214621e303aa"
          }
        },
        "58a03bffbbae4cbda871c0600a5808aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da5f6c3780e47df92d660dd8b241386",
            "max": 179999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7608c238f1040b886d6670d6e3ea5ee",
            "value": 179999
          }
        },
        "58feeb70efe34dab927a358d0d6ecc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61096862da17447b88364e9548243145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03486ecc6fed4a7cb7e2e02dca0dee5d",
            "max": 57101872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75e55e7d9e6b4e9f9c6bd2a84b811dc8",
            "value": 57101872
          }
        },
        "66370977f9974e2b992ed2fd4babc288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4aa01c89e047a5b8f18b3137ef72f4",
            "placeholder": "​",
            "style": "IPY_MODEL_1286473bfcdb4d5f96bc3154c26d72cc",
            "value": " 57.1M/57.1M [00:02&lt;00:00, 25.3MB/s]"
          }
        },
        "678ae2e0d9b644b79150918ccfb4da14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2947e714644297833248cdbbac3216",
            "max": 255644428,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58feeb70efe34dab927a358d0d6ecc6d",
            "value": 255644428
          }
        },
        "6a5e1968f6eb4e9e925a39b6003b9e96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a6fc018480541a7aea9b6e137f8f942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b4bc09dd88c4d0c9a52fb4b145d4819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4cdee9de6cb4bd1b3e6a314ebcc3299",
            "placeholder": "​",
            "style": "IPY_MODEL_2d74cb6cfd63483d99cf994bbecf53ee",
            "value": "Generating train split: 100%"
          }
        },
        "6da5f6c3780e47df92d660dd8b241386": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb18a43b7f742a285a8e6bd43e83599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d12030f83a134743bace242e6be5fdaf",
              "IPY_MODEL_61096862da17447b88364e9548243145",
              "IPY_MODEL_66370977f9974e2b992ed2fd4babc288"
            ],
            "layout": "IPY_MODEL_a84e8c06726b4ab196f4f27020d0f22f"
          }
        },
        "734221f5c5aa473497b1a3345bbbc80a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e55e7d9e6b4e9f9c6bd2a84b811dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77d756887b7d4c07bf898ac41f3e5433": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d05bb6c47dc460381c2a6af5266d875",
            "placeholder": "​",
            "style": "IPY_MODEL_faae37a536fb4037a323964dfa53a991",
            "value": "data/train-00000-of-00002.parquet: 100%"
          }
        },
        "7845466ec19946c5a076888a0f2341a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36eadf48405b4d60afdd702c6eabe976",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_271457a1a6a2478880ef17c92139a4a1",
            "value": 967
          }
        },
        "78a793bfcc2f4d22ac73e1d9396cc434": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a124143b0d44f8a19e0ed62921a15b",
            "placeholder": "​",
            "style": "IPY_MODEL_c80007e89d09489f8e4bcf9b3a5e9541",
            "value": " 967/967 [00:00&lt;00:00, 99.5kB/s]"
          }
        },
        "7c213b3ba59344c3a67d449b7fcf09fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7e3f254d06844cd8cbdb91f986c87fd",
              "IPY_MODEL_678ae2e0d9b644b79150918ccfb4da14",
              "IPY_MODEL_a41a577cf40f466f9580347278875674"
            ],
            "layout": "IPY_MODEL_6a5e1968f6eb4e9e925a39b6003b9e96"
          }
        },
        "7ca49bafcc404cc2a549128cbf2da144": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b4bc09dd88c4d0c9a52fb4b145d4819",
              "IPY_MODEL_58a03bffbbae4cbda871c0600a5808aa",
              "IPY_MODEL_246d3453758f4803b034aff39adaa8e4"
            ],
            "layout": "IPY_MODEL_ffe8eb62369b47739676e2fe28b64ff3"
          }
        },
        "7ca58392065c404d8f17909085f87875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3eaf210f8a434a36bff0ef7b61e53465",
              "IPY_MODEL_7845466ec19946c5a076888a0f2341a5",
              "IPY_MODEL_78a793bfcc2f4d22ac73e1d9396cc434"
            ],
            "layout": "IPY_MODEL_98b5693678be4a15a377234298821458"
          }
        },
        "86a124143b0d44f8a19e0ed62921a15b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89828f4b1f4449e3b52b8951a22054a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6700fbe79d40ec8261a68822c8c48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f167376d3cbd428caade36eede87371c",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e7293a253c54849b8cf7ab7407cd194",
            "value": 20000
          }
        },
        "8bc322a71765490d8bc40432329befff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e7293a253c54849b8cf7ab7407cd194": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98b5693678be4a15a377234298821458": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c02e19ab94422ea427d9e2fc9123c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43bcadc5c612457d8cfb8605889e27a5",
            "placeholder": "​",
            "style": "IPY_MODEL_43d4e788c9e3416fbd70cb9f360d7887",
            "value": " 255M/255M [00:03&lt;00:00, 112MB/s]"
          }
        },
        "99f65c3d847448b2947aef46e8a05b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a41a577cf40f466f9580347278875674": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d799f109f2a84e0ca8aae25d1dbfa194",
            "placeholder": "​",
            "style": "IPY_MODEL_8bc322a71765490d8bc40432329befff",
            "value": " 256M/256M [00:03&lt;00:00, 93.5MB/s]"
          }
        },
        "a7e3f254d06844cd8cbdb91f986c87fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_734221f5c5aa473497b1a3345bbbc80a",
            "placeholder": "​",
            "style": "IPY_MODEL_36910390b5da4091846ca5fcfbbf8a61",
            "value": "data/train-00001-of-00002.parquet: 100%"
          }
        },
        "a84e8c06726b4ab196f4f27020d0f22f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acfbe50fd14240cab4e34052d6f006b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b6de1dcf8c427898db39203794a3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77d756887b7d4c07bf898ac41f3e5433",
              "IPY_MODEL_d41ae3498e51438f97d70db96e8c3765",
              "IPY_MODEL_99c02e19ab94422ea427d9e2fc9123c8"
            ],
            "layout": "IPY_MODEL_3088b111494643b6bea2575b95888ac7"
          }
        },
        "b7608c238f1040b886d6670d6e3ea5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb6af5b3c5fc4bd1a249ecc33ce9687a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c31f976abb564d769ea56ebad2dc3ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a933565ab44e2588724492fc084f55",
            "placeholder": "​",
            "style": "IPY_MODEL_dec53c8d9a9f4648837725261e8b153f",
            "value": " 20000/20000 [00:00&lt;00:00, 55366.25 examples/s]"
          }
        },
        "c3c060dc723d415daf54a4bc703dcea0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c80007e89d09489f8e4bcf9b3a5e9541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca4aa01c89e047a5b8f18b3137ef72f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12030f83a134743bace242e6be5fdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_135c7d5ae19a46ee811002c6a139692c",
            "placeholder": "​",
            "style": "IPY_MODEL_f2fc60fc5389457ab7dbd1c6a4ad4ea6",
            "value": "data/test-00000-of-00001.parquet: 100%"
          }
        },
        "d41ae3498e51438f97d70db96e8c3765": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6af5b3c5fc4bd1a249ecc33ce9687a",
            "max": 255327096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99f65c3d847448b2947aef46e8a05b33",
            "value": 255327096
          }
        },
        "d799f109f2a84e0ca8aae25d1dbfa194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec53c8d9a9f4648837725261e8b153f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f167376d3cbd428caade36eede87371c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fc60fc5389457ab7dbd1c6a4ad4ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4cdee9de6cb4bd1b3e6a314ebcc3299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f769ee16de144e22a1ed214621e303aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83610de6c30471ab5d54786fe6236c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faae37a536fb4037a323964dfa53a991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffe8eb62369b47739676e2fe28b64ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
