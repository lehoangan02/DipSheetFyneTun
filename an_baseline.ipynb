{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUD0aErgQ0k9"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiTO6POiQ0k9"
      },
      "source": [
        "\n",
        "Introducing FP8 precision training for faster RL inference. [Read Blog](https://docs.unsloth.ai/new/fp8-reinforcement-learning).\n",
        "\n",
        "Unsloth's [Docker image](https://hub.docker.com/r/unsloth/unsloth) is here! Start training with no setup & environment issues. [Read our Guide](https://docs.unsloth.ai/new/how-to-train-llms-with-unsloth-and-docker).\n",
        "\n",
        "[gpt-oss RL](https://docs.unsloth.ai/new/gpt-oss-reinforcement-learning) is now supported with the fastest inference & lowest VRAM. Try our [new notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb) which creates kernels!\n",
        "\n",
        "Introducing [Vision](https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl) and [Standby](https://docs.unsloth.ai/basics/memory-efficient-rl) for RL! Train Qwen, Gemma etc. VLMs with GSPO - even faster with less VRAM.\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-omDWHxwQ0k9"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsXesNjCQ0k9"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    import torch; v = re.match(r\"[0-9]{1,}\\.[0-9]{1,}\", str(torch.__version__)).group(0)\n",
        "    xformers = \"xformers==\" + (\"0.0.33.post1\" if v==\"2.9\" else \"0.0.32.post2\" if v==\"2.8\" else \"0.0.29.post3\")\n",
        "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2\n",
        "!pip install jiwer\n",
        "!pip install einops addict easydict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsloth"
      ],
      "metadata": {
        "id": "aDUW7Efhid6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF4tERCWQ0k-"
      },
      "source": [
        "Let's prepare the OCR model to our local first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvYDYJdMQ0k-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811,
          "referenced_widgets": [
            "15f6bcd33ecf496782d1a75b1e0abf60",
            "ec0d955237d748529cd8ef9a01c3d841",
            "eccf5a3ccc0e481eaf9e316f6c6c4ee7",
            "527dd975fde44b6e81933340fb4aedfb",
            "1b9cc91cb5374445810843d4e41a550b",
            "ae8a81caabb94fc0832c2d7f67cdb2b7",
            "c5b4907ca31748e09e9123323dfd0718",
            "9f15f416994c408aa65f3e518340e9f4",
            "f26cc1bd09d8458b9cca166419341dc8",
            "c17b3632b24341f4b2898f864eec9cdc",
            "a200d999bf5046a082a0ab76bf03e735",
            "12230324554d44dc80cca9663982e7f5",
            "2bb94ffba02c4bd8be701bcdd3f72d11",
            "a441857923f043d2afe1a1ff9dba473f",
            "8b1cfcb5db3e47f0b0159e7cdc42713c",
            "c8249c786c894f31887a56d18de417eb",
            "6f118b10a639493195e27fb974161cb8",
            "3b80587917034ab3a4c819e665f56cfb",
            "eca46c9be2c044e3a6120e75fbfaf2e6",
            "ee8bd86999424ff6b934ea1e00d08b65",
            "8805f8055b5f4ab4929474e53ec16046",
            "bbb28a0f74dc49f2920f3039a8b3b145"
          ]
        },
        "outputId": "3ec5b87b-cc41-491b-8a24-ae8840effebd",
        "collapsed": true
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15f6bcd33ecf496782d1a75b1e0abf60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 21 files:   0%|          | 0/21 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0d955237d748529cd8ef9a01c3d841",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eccf5a3ccc0e481eaf9e316f6c6c4ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README-checkpoint.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "527dd975fde44b6e81933340fb4aedfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b9cc91cb5374445810843d4e41a550b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "LICENSE: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae8a81caabb94fc0832c2d7f67cdb2b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "assets/show2.jpg:   0%|          | 0.00/216k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5b4907ca31748e09e9123323dfd0718",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "assets/show1.jpg:   0%|          | 0.00/117k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f15f416994c408aa65f3e518340e9f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "assets/show3.jpg:   0%|          | 0.00/247k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f26cc1bd09d8458b9cca166419341dc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "assets/fig1.png:   0%|          | 0.00/396k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c17b3632b24341f4b2898f864eec9cdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_deepseek_v2.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a200d999bf5046a082a0ab76bf03e735",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "conversation.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12230324554d44dc80cca9663982e7f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bb94ffba02c4bd8be701bcdd3f72d11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "assets/show4.jpg:   0%|          | 0.00/269k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a441857923f043d2afe1a1ff9dba473f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "deepencoder.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b1cfcb5db3e47f0b0159e7cdc42713c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8249c786c894f31887a56d18de417eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_deepseekocr.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f118b10a639493195e27fb974161cb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-000001.safetensors:   0%|          | 0.00/6.67G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b80587917034ab3a4c819e665f56cfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_deepseekv2.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eca46c9be2c044e3a6120e75fbfaf2e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee8bd86999424ff6b934ea1e00d08b65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8805f8055b5f4ab4929474e53ec16046",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbb28a0f74dc49f2920f3039a8b3b145",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2198432777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unsloth/DeepSeek-OCR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"deepseek_ocr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/_snapshot_download.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0m_inner_hf_hub_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         thread_map(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0m_inner_hf_hub_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mfiltered_repo_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_executor_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         with PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[1;32m     50\u001b[0m                           initargs=(lk,)) as ex:\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    617\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(\"unsloth/DeepSeek-OCR\", local_dir = \"deepseek_ocr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
        "import torch\n",
        "from transformers import AutoModel\n",
        "import os\n",
        "os.environ[\"UNSLOTH_WARN_UNINITIALIZED\"] = '0'\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Qwen3-VL-8B-Instruct-bnb-4bit\", # Qwen 3 vision support\n",
        "    \"unsloth/Qwen3-VL-8B-Thinking-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-VL-32B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-VL-32B-Thinking-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"./deepseek_ocr\",\n",
        "    load_in_4bit = False, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    auto_model = AutoModel,\n",
        "    trust_remote_code=True,\n",
        "    unsloth_force_compile=True,\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O dataset.zip \"https://huggingface.co/datasets/lehoangan02/nlp/resolve/main/dataset.zip?download=true\"\n",
        "!unzip -q dataset.zip"
      ],
      "metadata": {
        "id": "sa7Ukki0ysZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load raw JSON. Do NOT process images here.\n",
        "dataset_train = load_dataset(\"json\", data_files=\"dataset/deepseek_train.json\")[\"train\"]\n",
        "dataset_val   = load_dataset(\"json\", data_files=\"dataset/deepseek_val.json\")[\"train\"]\n",
        "\n",
        "# Assign to the variables expected by the Trainer\n",
        "a = dataset_train\n",
        "converted_val = dataset_val\n",
        "converted_train = dataset_train\n",
        "\n",
        "print(f\"Train samples: {len(converted_train)}\")\n",
        "print(f\"Val samples: {len(converted_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCTD80dOyLrG"
      },
      "outputs": [],
      "source": [
        "sample = dataset_val[0]\n",
        "sample['messages'][0]['images'][0]  # for image\n",
        "sample['messages'][1]['content']   # for OCR text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZHjLlxrI_TH"
      },
      "outputs": [],
      "source": [
        "# Save an image that will not be used during training for evaluation purposes\n",
        "from PIL import Image\n",
        "\n",
        "# Example: pick first sample in validation set\n",
        "sample = dataset_val[0]\n",
        "image_path = sample['messages'][0]['images'][0]  # path from your JSON\n",
        "Image.open(image_path).save(\"your_image.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "3d626808",
        "outputId": "f40f9405-9a56-45ab-a082-0c8326cb713d"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename='your_image.jpg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6LYHC3F0Ihf"
      },
      "source": [
        "<h3>Baseline Model Performance: 23% Character Error Rate (CER) for this sample !</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzckMII_02s_"
      },
      "source": [
        "# Let's finetune Deepseek-OCR !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters for parameter efficient finetuning - this allows us to only efficiently train 1% of all parameters.\n",
        "\n",
        "**[NEW]** We also support finetuning ONLY the vision part of the model, or ONLY the language part. Or you can select both! You can also select to finetune the attention or the MLP layers!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "b26ea0f2-169d-4269-ba1e-37cc67635448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `model.base_model.model.model` require gradients\n"
          ]
        }
      ],
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "\n",
        "    r = 16,           # The larger, the higher the accuracy, but might overfit\n",
        "    lora_alpha = 16,  # Recommended alpha == r at least\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "# Data prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "To format the dataset, all vision finetuning tasks should be formatted as follows:\n",
        "\n",
        "```python\n",
        "[\n",
        "{ \"role\": \"<|User|>\",\n",
        "  \"content\": \"\",\n",
        "  \"images\": []\n",
        "},\n",
        "{ \"role\": \"<|Assistant|>\",\n",
        "  \"content\": \"\"\n",
        "},\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXzJZzHEgXe"
      },
      "outputs": [],
      "source": [
        "instruction = \"<image>\\nFree OCR. \"\n",
        "\n",
        "def convert_to_conversation(sample):\n",
        "    \"\"\"Convert dataset sample to conversation format\"\"\"\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"<|User|>\",\n",
        "            \"content\": instruction,\n",
        "            \"images\": [sample['image']]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"<|Assistant|>\",\n",
        "            \"content\": sample[\"text\"]\n",
        "        },\n",
        "    ]\n",
        "    return {\"messages\": conversation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY-9u-OD6_gE"
      },
      "source": [
        "Let's convert the dataset into the \"correct\" format for finetuning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for the first example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2WR-p20LcG_"
      },
      "outputs": [],
      "source": [
        "# @title Create datacollator\n",
        "\n",
        "import torch\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Any, Tuple\n",
        "from PIL import Image, ImageOps\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import io\n",
        "\n",
        "from deepseek_ocr.modeling_deepseekocr import (\n",
        "    format_messages,\n",
        "    text_encode,\n",
        "    BasicImageTransform,\n",
        "    dynamic_preprocess,\n",
        ")\n",
        "\n",
        "@dataclass\n",
        "class DeepSeekOCRDataCollator:\n",
        "    tokenizer: Any\n",
        "    model: Any\n",
        "    image_size: int = 640\n",
        "    base_size: int = 1024\n",
        "    crop_mode: bool = True\n",
        "    image_token_id: int = 128815\n",
        "    train_on_responses_only: bool = True\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        model,\n",
        "        image_size: int = 640,\n",
        "        base_size: int = 1024,\n",
        "        crop_mode: bool = True,\n",
        "        train_on_responses_only: bool = True,\n",
        "    ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "        self.image_size = image_size\n",
        "        self.base_size = base_size\n",
        "        self.crop_mode = crop_mode\n",
        "        self.image_token_id = 128815\n",
        "        self.dtype = model.dtype\n",
        "        self.train_on_responses_only = train_on_responses_only\n",
        "\n",
        "        self.image_transform = BasicImageTransform(\n",
        "            mean=(0.5, 0.5, 0.5),\n",
        "            std=(0.5, 0.5, 0.5),\n",
        "            normalize=True\n",
        "        )\n",
        "        self.patch_size = 16\n",
        "        self.downsample_ratio = 4\n",
        "\n",
        "        if hasattr(tokenizer, 'bos_token_id') and tokenizer.bos_token_id is not None:\n",
        "            self.bos_id = tokenizer.bos_token_id\n",
        "        else:\n",
        "            self.bos_id = 0\n",
        "\n",
        "    def deserialize_image(self, image_data) -> Image.Image:\n",
        "        # THIS IS THE FIX: Handle file paths (strings) directly\n",
        "        if isinstance(image_data, str):\n",
        "            try:\n",
        "                return Image.open(image_data).convert(\"RGB\")\n",
        "            except Exception as e:\n",
        "                # Create a black placeholder image if loading fails to prevent crash\n",
        "                print(f\"Error loading image {image_data}: {e}\")\n",
        "                return Image.new('RGB', (100, 100), color='black')\n",
        "        elif isinstance(image_data, Image.Image):\n",
        "            return image_data.convert(\"RGB\")\n",
        "        elif isinstance(image_data, dict) and 'bytes' in image_data:\n",
        "            image_bytes = image_data['bytes']\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            return image.convert(\"RGB\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported image format: {type(image_data)}\")\n",
        "\n",
        "    def calculate_image_token_count(self, image: Image.Image, crop_ratio: Tuple[int, int]) -> int:\n",
        "        num_queries = math.ceil((self.image_size // self.patch_size) / self.downsample_ratio)\n",
        "        num_queries_base = math.ceil((self.base_size // self.patch_size) / self.downsample_ratio)\n",
        "        width_crop_num, height_crop_num = crop_ratio\n",
        "\n",
        "        if self.crop_mode:\n",
        "            img_tokens = num_queries_base * num_queries_base + 1\n",
        "            if width_crop_num > 1 or height_crop_num > 1:\n",
        "                img_tokens += (num_queries * width_crop_num + 1) * (num_queries * height_crop_num)\n",
        "        else:\n",
        "            img_tokens = num_queries * num_queries + 1\n",
        "        return img_tokens\n",
        "\n",
        "    def process_image(self, image: Image.Image) -> Tuple[List, List, List, List, Tuple[int, int]]:\n",
        "        images_list = []\n",
        "        images_crop_list = []\n",
        "        images_spatial_crop = []\n",
        "\n",
        "        if self.crop_mode:\n",
        "            if image.size[0] <= 640 and image.size[1] <= 640:\n",
        "                crop_ratio = (1, 1)\n",
        "                images_crop_raw = []\n",
        "            else:\n",
        "                images_crop_raw, crop_ratio = dynamic_preprocess(\n",
        "                    image, min_num=2, max_num=9,\n",
        "                    image_size=self.image_size, use_thumbnail=False\n",
        "                )\n",
        "\n",
        "            global_view = ImageOps.pad(\n",
        "                image, (self.base_size, self.base_size),\n",
        "                color=tuple(int(x * 255) for x in self.image_transform.mean)\n",
        "            )\n",
        "            images_list.append(self.image_transform(global_view).to(self.dtype))\n",
        "\n",
        "            width_crop_num, height_crop_num = crop_ratio\n",
        "            images_spatial_crop.append([width_crop_num, height_crop_num])\n",
        "\n",
        "            if width_crop_num > 1 or height_crop_num > 1:\n",
        "                for crop_img in images_crop_raw:\n",
        "                    images_crop_list.append(self.image_transform(crop_img).to(self.dtype))\n",
        "\n",
        "            num_queries = math.ceil((self.image_size // self.patch_size) / self.downsample_ratio)\n",
        "            num_queries_base = math.ceil((self.base_size // self.patch_size) / self.downsample_ratio)\n",
        "\n",
        "            tokenized_image = ([self.image_token_id] * num_queries_base + [self.image_token_id]) * num_queries_base\n",
        "            tokenized_image += [self.image_token_id]\n",
        "\n",
        "            if width_crop_num > 1 or height_crop_num > 1:\n",
        "                tokenized_image += ([self.image_token_id] * (num_queries * width_crop_num) + [self.image_token_id]) * (\n",
        "                    num_queries * height_crop_num)\n",
        "\n",
        "        else:\n",
        "            crop_ratio = (1, 1)\n",
        "            images_spatial_crop.append([1, 1])\n",
        "            if self.base_size <= 640:\n",
        "                resized_image = image.resize((self.base_size, self.base_size), Image.LANCZOS)\n",
        "                images_list.append(self.image_transform(resized_image).to(self.dtype))\n",
        "            else:\n",
        "                global_view = ImageOps.pad(\n",
        "                    image, (self.base_size, self.base_size),\n",
        "                    color=tuple(int(x * 255) for x in self.image_transform.mean)\n",
        "                )\n",
        "                images_list.append(self.image_transform(global_view).to(self.dtype))\n",
        "\n",
        "            num_queries = math.ceil((self.base_size // self.patch_size) / self.downsample_ratio)\n",
        "            tokenized_image = ([self.image_token_id] * num_queries + [self.image_token_id]) * num_queries\n",
        "            tokenized_image += [self.image_token_id]\n",
        "\n",
        "        return images_list, images_crop_list, images_spatial_crop, tokenized_image, crop_ratio\n",
        "\n",
        "    def process_single_sample(self, messages: List[Dict]) -> Dict[str, Any]:\n",
        "            images = []\n",
        "            for message in messages:\n",
        "                if \"images\" in message and message[\"images\"]:\n",
        "                    for img_data in message[\"images\"]:\n",
        "                        if img_data is not None:\n",
        "                            pil_image = self.deserialize_image(img_data)\n",
        "                            images.append(pil_image)\n",
        "\n",
        "            if not images:\n",
        "                # Fallback for text-only or missing image\n",
        "                images.append(Image.new('RGB', (100, 100), color='black'))\n",
        "\n",
        "            tokenized_str = []\n",
        "            images_seq_mask = []\n",
        "            images_list, images_crop_list, images_spatial_crop = [], [], []\n",
        "            prompt_token_count = -1\n",
        "            assistant_started = False\n",
        "            image_idx = 0\n",
        "\n",
        "            tokenized_str.append(self.bos_id)\n",
        "            images_seq_mask.append(False)\n",
        "\n",
        "            for message in messages:\n",
        "                role = message[\"role\"]\n",
        "                content = message[\"content\"]\n",
        "\n",
        "                if role == \"<|Assistant|>\":\n",
        "                    if not assistant_started:\n",
        "                        prompt_token_count = len(tokenized_str)\n",
        "                        assistant_started = True\n",
        "                    content = f\"{content.strip()} {self.tokenizer.eos_token}\"\n",
        "\n",
        "                text_splits = content.split('<image>')\n",
        "                for i, text_sep in enumerate(text_splits):\n",
        "                    tokenized_sep = text_encode(self.tokenizer, text_sep, bos=False, eos=False)\n",
        "                    tokenized_str.extend(tokenized_sep)\n",
        "                    images_seq_mask.extend([False] * len(tokenized_sep))\n",
        "\n",
        "                    if i < len(text_splits) - 1:\n",
        "                        if image_idx < len(images):\n",
        "                            image = images[image_idx]\n",
        "                            img_list, crop_list, spatial_crop, tok_img, _ = self.process_image(image)\n",
        "                            images_list.extend(img_list)\n",
        "                            images_crop_list.extend(crop_list)\n",
        "                            images_spatial_crop.extend(spatial_crop)\n",
        "                            tokenized_str.extend(tok_img)\n",
        "                            images_seq_mask.extend([True] * len(tok_img))\n",
        "                            image_idx += 1\n",
        "\n",
        "            images_ori = torch.stack(images_list, dim=0)\n",
        "            images_spatial_crop_tensor = torch.tensor(images_spatial_crop, dtype=torch.long)\n",
        "            if images_crop_list:\n",
        "                images_crop = torch.stack(images_crop_list, dim=0)\n",
        "            else:\n",
        "                images_crop = torch.zeros((1, 3, self.base_size, self.base_size), dtype=self.dtype)\n",
        "\n",
        "            return {\n",
        "                \"input_ids\": torch.tensor(tokenized_str, dtype=torch.long),\n",
        "                \"images_seq_mask\": torch.tensor(images_seq_mask, dtype=torch.bool),\n",
        "                \"images_ori\": images_ori,\n",
        "                \"images_crop\": images_crop,\n",
        "                \"images_spatial_crop\": images_spatial_crop_tensor,\n",
        "                \"prompt_token_count\": prompt_token_count,\n",
        "            }\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
        "        batch_data = []\n",
        "        for feature in features:\n",
        "            try:\n",
        "                processed = self.process_single_sample(feature['messages'])\n",
        "                batch_data.append(processed)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sample: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not batch_data:\n",
        "            # Emergency fallback to prevent crash if entire batch fails\n",
        "            raise ValueError(\"No valid samples in batch\")\n",
        "\n",
        "        input_ids = pad_sequence([x['input_ids'] for x in batch_data], batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "        images_seq_mask = pad_sequence([x['images_seq_mask'] for x in batch_data], batch_first=True, padding_value=False)\n",
        "        labels = input_ids.clone()\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "        labels[images_seq_mask] = -100\n",
        "\n",
        "        if self.train_on_responses_only:\n",
        "            for idx, item in enumerate(batch_data):\n",
        "                if item['prompt_token_count'] > 0:\n",
        "                    labels[idx, :item['prompt_token_count']] = -100\n",
        "\n",
        "        attention_mask = (input_ids != self.tokenizer.pad_token_id).long()\n",
        "        images_batch = [(x['images_crop'], x['images_ori']) for x in batch_data]\n",
        "        images_spatial_crop = torch.cat([x['images_spatial_crop'] for x in batch_data], dim=0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels,\n",
        "            \"images\": images_batch,\n",
        "            \"images_seq_mask\": images_seq_mask,\n",
        "            \"images_spatial_crop\": images_spatial_crop,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's train our model. We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!\n",
        "\n",
        "We use our new `DeepSeekOCRDataCollator` which will help in our vision finetuning setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95_Nn-89DhsL",
        "outputId": "43d1f82d-c02e-48a2-f1d3-4e9a6aeda630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-701024634.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer._unsloth___init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from unsloth import is_bf16_supported\n",
        "FastVisionModel.for_training(model) # Enable for training!\n",
        "data_collator = DeepSeekOCRDataCollator(\n",
        "    tokenizer=tokenizer,\n",
        "    model = model,\n",
        "    image_size=640,\n",
        "    base_size=1024,\n",
        "    crop_mode=True,\n",
        "    train_on_responses_only=True,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = data_collator, # Must use!\n",
        "    train_dataset = converted_train,\n",
        "    eval_dataset  = converted_val,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        # num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.001,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        fp16 = not is_bf16_supported(),  # Use fp16 if bf16 is not supported\n",
        "        bf16 = is_bf16_supported(),  # Use bf16 if supported\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",     # For Weights and Biases\n",
        "        dataloader_num_workers=2,\n",
        "        # You MUST put the below items for vision finetuning:\n",
        "        remove_unused_columns = False,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "faba9ee5-dc51-4c9f-c102-c4c04a3b0091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "6.855 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "c64330ac-30c1-4df7-e2b7-81edd0837e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 96,846 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 77,509,632 of 3,413,615,872 (2.27% trained)\n",
            "Unsloth: Not an error, but DeepseekOCRForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 14:22, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.452400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.863700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.635200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.650300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.424200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.823400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.195100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.612300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.876300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.791100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.928400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.868900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.644300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.445100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.511800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.035100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.420400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.230200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.175200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.327200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.263200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.964000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.988200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.052900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.049900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.627700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.221400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.720500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.766600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.755400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.317300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.876700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.982800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.768800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.857600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.530800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.410700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.263700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.375200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.154700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.191600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.124000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.934700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.269000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.980100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.947900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.466700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.539700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.859100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.359600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.162500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.890900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([4, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([2, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n",
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([6, 100, 1280])\n",
            "=====================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n"
          ]
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45516231-a050-418c-e0b2-e3617905ec58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "884.8921 seconds used for training.\n",
            "14.75 minutes used for training.\n",
            "Peak reserved memory = 10.57 GB.\n",
            "Peak reserved memory for training = 3.715 GB.\n",
            "Peak reserved memory % of max memory = 71.705 %.\n",
            "Peak reserved memory for training % of max memory = 25.202 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "b9939f3d-2d63-432a-a782-5b8619bf5254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '\\nFree OCR.']\n",
            "    \n",
            "===============save results:===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "prompt = \"<image>\\nFree OCR. \"\n",
        "image_file = 'your_image.jpg'\n",
        "output_path = './output'\n",
        "\n",
        "# Tiny: base_size = 512, image_size = 512, crop_mode = False\n",
        "# Small: base_size = 640, image_size = 640, crop_mode = False\n",
        "# Base: base_size = 1024, image_size = 1024, crop_mode = False\n",
        "# Large: base_size = 1280, image_size = 1280, crop_mode = False\n",
        "\n",
        "# Gundam: base_size = 1024, image_size = 640, crop_mode = True\n",
        "\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file,\n",
        "    output_path = output_path,\n",
        "    image_size=640,\n",
        "    base_size=1024,\n",
        "    crop_mode=True,\n",
        "    save_results = True,\n",
        "    test_compress = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd30-Yg3fEeK"
      },
      "source": [
        "With only 60 steps, we dramatically improved the transcription quality. The Character Error Rate (CER) on this single sample dropped from 23% to 6%, a 74% relative reduction!\n",
        "\n",
        "| Type | OCR |\n",
        "| :--- | :--- |\n",
        "| **Baseline (Pre-Finetune)** | `    ` |\n",
        "| **Finetuned (60 steps)** | `    ` |\n",
        "| **Ground Truth** | `    ` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "fcc03501-3858-46d4-adba-75514361c04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('lora_model', 'zip', 'lora_model')\n",
        "\n",
        "# Download the zip file\n",
        "files.download('lora_model.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "VTX_jq6fC_-O",
        "outputId": "6d14ef46-21b7-4fcb-f6a3-9e2364fa9350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b921c6b7-9e00-4dcc-b92e-96cfca1804e7\", \"lora_model.zip\", 283493348)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKX_XKs_BNZR"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    from unsloth import FastVisionModel\n",
        "    model, tokenizer = FastVisionModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = False, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "        auto_model = AutoModel,\n",
        "        trust_remote_code=True,\n",
        "        unsloth_force_compile=True,\n",
        "        use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        "    )\n",
        "    FastVisionModel.for_inference(model) # Enable for inference!\n",
        "\n",
        "prompt = \"<image>\\nFree OCR. \"\n",
        "image_file = 'your_image.jpg'\n",
        "output_path = './output'\n",
        "\n",
        "# Tiny: base_size = 512, image_size = 512, crop_mode = False\n",
        "# Small: base_size = 640, image_size = 640, crop_mode = False\n",
        "# Base: base_size = 1024, image_size = 1024, crop_mode = False\n",
        "# Large: base_size = 1280, image_size = 1280, crop_mode = False\n",
        "\n",
        "# Gundam: base_size = 1024, image_size = 640, crop_mode = True\n",
        "\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file,\n",
        "    output_path = output_path,\n",
        "    image_size=640,\n",
        "    base_size=1024,\n",
        "    crop_mode=True,\n",
        "    save_results = True,\n",
        "    test_compress = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Select ONLY 1 to save! (Both not needed!)\n",
        "\n",
        "# Save locally to 16bit\n",
        "if False: model.save_pretrained_merged(\"unsloth_finetune\", tokenizer,)\n",
        "\n",
        "# To export and save to your Hugging Face account\n",
        "if False: model.push_to_hub_merged(\"YOUR_USERNAME/unsloth_finetune\", tokenizer, token = \"PUT_HERE\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}